{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A case study using iris dataset for KNN algorithm "
      ],
      "metadata": {
        "id": "bca1ZpDIsGD6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwk6dOM0E8Od",
        "outputId": "a5cd4db6-4d1e-4944-d601-208790fefb8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions from the classifier:\n",
            "[0 2 0 1 2 2 2 0 2 0 1 0 0 0 1 2 2 1 0 2 0 1 2 1 0 2 1 1 0 0]\n",
            "Target values:\n",
            "[0 2 0 1 2 2 2 0 2 0 1 0 0 0 1 2 2 1 0 1 0 1 2 1 0 2 1 1 0 0]\n",
            "0.9666666666666667\n",
            "Predictions from the classifier:\n",
            "[0 1 2 0 2 0 1 1 0 1 1 0 0 0 0 0 0 0 2 0 2 1 1 1 0 2 1 1 2 0 2 0 2 1 2 2 1\n",
            " 1 1 2 2 0 2 2 0 1 0 2 2 0 1 1 0 0 1 1 1 1 2 1 2 0 0 1 1 2 0 2 1 0 2 2 1 2\n",
            " 2 0 0 2 1 1 2 0 1 1 0 1 1 2 2 1 0 2 0 2 0 0 1 2 2 1 2 2 0 1 1 0 2 2 2 1 2\n",
            " 2 2 0 0 1 0 2 2 1]\n",
            "Target values:\n",
            "[0 1 2 0 2 0 1 1 0 1 1 0 0 0 0 0 0 0 2 0 2 1 1 1 0 2 1 1 2 0 2 0 2 2 2 2 1\n",
            " 1 1 1 2 0 2 2 0 1 0 2 2 0 1 1 0 0 1 1 1 1 2 1 2 0 0 1 1 1 0 2 1 0 2 2 1 2\n",
            " 2 0 0 2 1 1 2 0 1 1 0 1 1 2 2 1 0 2 0 2 0 0 1 2 2 1 2 2 0 1 1 0 2 2 2 1 2\n",
            " 2 2 0 0 1 0 2 2 1]\n",
            "0.975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# import modules for this project\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load iris dataset\n",
        "iris = datasets.load_iris()\n",
        "data, labels = iris.data, iris.target\n",
        "\n",
        "# training testing split\n",
        "res = train_test_split(data, labels, \n",
        "                       train_size=0.8,\n",
        "                       test_size=0.2,\n",
        "                       random_state=12)\n",
        "train_data, test_data, train_labels, test_labels = res \n",
        "\n",
        "# Create and fit a nearest-neighbor classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# classifier \"out of the box\", no parameters\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_data, train_labels) \n",
        "\n",
        "# print some interested metrics\n",
        "print(\"Predictions from the classifier:\")\n",
        "learn_data_predicted = knn.predict(train_data)\n",
        "print(learn_data_predicted)\n",
        "print(\"Target values:\")\n",
        "print(train_labels)\n",
        "print(accuracy_score(learn_data_predicted, train_labels))\n",
        "\n",
        "# re-do KNN using some specific parameters. \n",
        "knn2 = KNeighborsClassifier(algorithm='auto', \n",
        "                            leaf_size=30, \n",
        "                            metric='minkowski',\n",
        "                            p=2,         # p=2 is equivalent to euclidian distance\n",
        "                            metric_params=None, \n",
        "                            n_jobs=1, \n",
        "                            n_neighbors=5, \n",
        "                            weights='uniform')\n",
        "\n",
        "knn.fit(train_data, train_labels) \n",
        "test_data_predicted = knn.predict(test_data)\n",
        "accuracy_score(test_data_predicted, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this command to help with choice of paramters in the `KNeighborsClassifier` function. "
      ],
      "metadata": {
        "id": "EGCbBcE5v3Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(KNeighborsClassifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08A9rmgQ5RQW",
        "outputId": "5133df49-a36d-42d5-f8b6-36a295ba448d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n",
            "\n",
            "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
            " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
            " |  \n",
            " |  Classifier implementing the k-nearest neighbors vote.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <classification>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  n_neighbors : int, default=5\n",
            " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
            " |  \n",
            " |  weights : {'uniform', 'distance'} or callable, default='uniform'\n",
            " |      Weight function used in prediction.  Possible values:\n",
            " |  \n",
            " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
            " |        are weighted equally.\n",
            " |      - 'distance' : weight points by the inverse of their distance.\n",
            " |        in this case, closer neighbors of a query point will have a\n",
            " |        greater influence than neighbors which are further away.\n",
            " |      - [callable] : a user-defined function which accepts an\n",
            " |        array of distances, and returns an array of the same shape\n",
            " |        containing the weights.\n",
            " |  \n",
            " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
            " |      Algorithm used to compute the nearest neighbors:\n",
            " |  \n",
            " |      - 'ball_tree' will use :class:`BallTree`\n",
            " |      - 'kd_tree' will use :class:`KDTree`\n",
            " |      - 'brute' will use a brute-force search.\n",
            " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
            " |        based on the values passed to :meth:`fit` method.\n",
            " |  \n",
            " |      Note: fitting on sparse input will override the setting of\n",
            " |      this parameter, using brute force.\n",
            " |  \n",
            " |  leaf_size : int, default=30\n",
            " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
            " |      speed of the construction and query, as well as the memory\n",
            " |      required to store the tree.  The optimal value depends on the\n",
            " |      nature of the problem.\n",
            " |  \n",
            " |  p : int, default=2\n",
            " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
            " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
            " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
            " |  \n",
            " |  metric : str or callable, default='minkowski'\n",
            " |      The distance metric to use for the tree.  The default metric is\n",
            " |      minkowski, and with p=2 is equivalent to the standard Euclidean\n",
            " |      metric. For a list of available metrics, see the documentation of\n",
            " |      :class:`~sklearn.metrics.DistanceMetric`.\n",
            " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
            " |      must be square during fit. X may be a :term:`sparse graph`,\n",
            " |      in which case only \"nonzero\" elements may be considered neighbors.\n",
            " |  \n",
            " |  metric_params : dict, default=None\n",
            " |      Additional keyword arguments for the metric function.\n",
            " |  \n",
            " |  n_jobs : int, default=None\n",
            " |      The number of parallel jobs to run for neighbors search.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |      Doesn't affect :meth:`fit` method.\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  classes_ : array of shape (n_classes,)\n",
            " |      Class labels known to the classifier\n",
            " |  \n",
            " |  effective_metric_ : str or callble\n",
            " |      The distance metric used. It will be same as the `metric` parameter\n",
            " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
            " |      'minkowski' and `p` parameter set to 2.\n",
            " |  \n",
            " |  effective_metric_params_ : dict\n",
            " |      Additional keyword arguments for the metric function. For most metrics\n",
            " |      will be same with `metric_params` parameter, but may also contain the\n",
            " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
            " |      'minkowski'.\n",
            " |  \n",
            " |  n_features_in_ : int\n",
            " |      Number of features seen during :term:`fit`.\n",
            " |  \n",
            " |      .. versionadded:: 0.24\n",
            " |  \n",
            " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
            " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
            " |      has feature names that are all strings.\n",
            " |  \n",
            " |      .. versionadded:: 1.0\n",
            " |  \n",
            " |  n_samples_fit_ : int\n",
            " |      Number of samples in the fitted data.\n",
            " |  \n",
            " |  outputs_2d_ : bool\n",
            " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
            " |      otherwise True.\n",
            " |  \n",
            " |  See Also\n",
            " |  --------\n",
            " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
            " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
            " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
            " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
            " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
            " |  \n",
            " |  .. warning::\n",
            " |  \n",
            " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
            " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
            " |     but different labels, the results will depend on the ordering of the\n",
            " |     training data.\n",
            " |  \n",
            " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> X = [[0], [1], [2], [3]]\n",
            " |  >>> y = [0, 0, 1, 1]\n",
            " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
            " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
            " |  >>> neigh.fit(X, y)\n",
            " |  KNeighborsClassifier(...)\n",
            " |  >>> print(neigh.predict([[1.1]]))\n",
            " |  [0]\n",
            " |  >>> print(neigh.predict_proba([[0.9]]))\n",
            " |  [[0.666... 0.333...]]\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      KNeighborsClassifier\n",
            " |      sklearn.neighbors._base.KNeighborsMixin\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      sklearn.neighbors._base.NeighborsBase\n",
            " |      sklearn.base.MultiOutputMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  fit(self, X, y)\n",
            " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
            " |          Training data.\n",
            " |      \n",
            " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
            " |          Target values.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : KNeighborsClassifier\n",
            " |          The fitted k-nearest neighbors classifier.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict the class labels for the provided data.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
            " |          Test samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
            " |          Class labels for each data sample.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Return probability estimates for the test data X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
            " |          Test samples.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
            " |          The class probabilities of the input samples. Classes are ordered\n",
            " |          by lexicographic order.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
            " |  \n",
            " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
            " |      Find the K-neighbors of a point.\n",
            " |      \n",
            " |      Returns indices of and distances to the neighbors of each point.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
            " |          The query point or points.\n",
            " |          If not provided, neighbors of each indexed point are returned.\n",
            " |          In this case, the query point is not considered its own neighbor.\n",
            " |      \n",
            " |      n_neighbors : int, default=None\n",
            " |          Number of neighbors required for each sample. The default is the\n",
            " |          value passed to the constructor.\n",
            " |      \n",
            " |      return_distance : bool, default=True\n",
            " |          Whether or not to return the distances.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
            " |          Array representing the lengths to points, only present if\n",
            " |          return_distance=True.\n",
            " |      \n",
            " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
            " |          Indices of the nearest points in the population matrix.\n",
            " |      \n",
            " |      Examples\n",
            " |      --------\n",
            " |      In the following example, we construct a NearestNeighbors\n",
            " |      class from an array representing our data set and ask who's\n",
            " |      the closest point to [1,1,1]\n",
            " |      \n",
            " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
            " |      >>> from sklearn.neighbors import NearestNeighbors\n",
            " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
            " |      >>> neigh.fit(samples)\n",
            " |      NearestNeighbors(n_neighbors=1)\n",
            " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
            " |      (array([[0.5]]), array([[2]]))\n",
            " |      \n",
            " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
            " |      element is at distance 0.5 and is the third element of samples\n",
            " |      (indexes start at 0). You can also query for multiple points:\n",
            " |      \n",
            " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
            " |      >>> neigh.kneighbors(X, return_distance=False)\n",
            " |      array([[1],\n",
            " |             [2]]...)\n",
            " |  \n",
            " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
            " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed',                 default=None\n",
            " |          The query point or points.\n",
            " |          If not provided, neighbors of each indexed point are returned.\n",
            " |          In this case, the query point is not considered its own neighbor.\n",
            " |          For ``metric='precomputed'`` the shape should be\n",
            " |          (n_queries, n_indexed). Otherwise the shape should be\n",
            " |          (n_queries, n_features).\n",
            " |      \n",
            " |      n_neighbors : int, default=None\n",
            " |          Number of neighbors for each sample. The default is the value\n",
            " |          passed to the constructor.\n",
            " |      \n",
            " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
            " |          Type of returned matrix: 'connectivity' will return the\n",
            " |          connectivity matrix with ones and zeros, in 'distance' the\n",
            " |          edges are distances between points, type of distance\n",
            " |          depends on the selected metric parameter in\n",
            " |          NearestNeighbors class.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
            " |          `n_samples_fit` is the number of samples in the fitted data.\n",
            " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
            " |          The matrix is of CSR format.\n",
            " |      \n",
            " |      See Also\n",
            " |      --------\n",
            " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
            " |          of Neighbors for points in X.\n",
            " |      \n",
            " |      Examples\n",
            " |      --------\n",
            " |      >>> X = [[0], [3], [1]]\n",
            " |      >>> from sklearn.neighbors import NearestNeighbors\n",
            " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
            " |      >>> neigh.fit(X)\n",
            " |      NearestNeighbors(n_neighbors=2)\n",
            " |      >>> A = neigh.kneighbors_graph(X)\n",
            " |      >>> A.toarray()\n",
            " |      array([[1., 0., 1.],\n",
            " |             [0., 1., 1.],\n",
            " |             [1., 0., 1.]])\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : dict\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
            " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
            " |      possible to update each component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : estimator instance\n",
            " |          Estimator instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the following code to generate an artificial dataset which contain three classes. Conduct a similar KNN analysis to the dataset and report your accuracy. "
      ],
      "metadata": {
        "id": "tws-xX2F5WH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "centers = [[2, 4], [6, 6], [1, 9]]\n",
        "n_classes = len(centers)\n",
        "data, labels = make_blobs(n_samples=420, \n",
        "                          centers=np.array(centers),\n",
        "                          random_state=1)\n",
        "# do a 80-20 split of the data\n",
        "res = train_test_split(data, labels, \n",
        "                       train_size=0.8,\n",
        "                       test_size=0.2,\n",
        "                       random_state=12)\n",
        "train_data, test_data, train_labels, test_labels = res \n",
        "\n",
        "# perform a KNN analysis of the simulated data\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# classifier \"out of the box\", no parameters\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(train_data, train_labels) \n",
        "\n",
        "# print some interested metrics\n",
        "learn_data_predicted = knn.predict(train_data)\n",
        "print(learn_data_predicted)\n",
        "print(train_labels)\n",
        "# output accuracy score\n",
        "print(accuracy_score(learn_data_predicted, train_labels))\n",
        "\n",
        "# plot your different results\n",
        "\n",
        "\n",
        "nhom_0 = []\n",
        "nhom_1 = []\n",
        "nhom_2 = []\n",
        "for i in range(420):\n",
        "    if labels[i] == 0:\n",
        "        nhom_0.append([data[i,0], data[i,1]])\n",
        "    elif labels[i] == 1:\n",
        "        nhom_1.append([data[i,0], data[i,1]])\n",
        "    else :\n",
        "        nhom_2.append([data[i,0], data[i,1]])\n",
        "nhom_0 = np.array(nhom_0)\n",
        "nhom_1 = np.array(nhom_1)\n",
        "nhom_2 = np.array(nhom_2)\n",
        "\n",
        "plt.plot(nhom_0[:,0], nhom_0[:,1], 'go', markersize = 3)\n",
        "plt.plot(nhom_1[:,0], nhom_1[:,1], 'ro', markersize = 3)\n",
        "plt.plot(nhom_2[:,0], nhom_2[:,1], 'bo', markersize = 3)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TwdApZEQwTz9",
        "outputId": "41d2540a-e9be-4fb7-e207-48f45b30bdac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 2 2 0 1 2 1 0 2 1 2 1 0 2 0 0 2 1 2 1 0 0 2 2 0 1 2 2 1 0 0 0 1 0 2 1\n",
            " 2 1 2 0 2 1 0 1 1 1 0 2 1 1 2 0 0 1 2 2 0 0 1 1 0 2 1 2 0 1 0 1 2 1 1 0 1\n",
            " 2 1 1 0 0 2 2 1 1 2 1 2 0 1 0 0 0 0 1 2 2 2 1 2 0 2 1 1 0 1 2 0 0 0 0 1 1\n",
            " 0 1 0 0 2 0 0 1 2 0 0 2 2 0 0 0 1 1 1 0 2 1 0 1 0 1 2 1 0 2 0 0 0 2 0 2 0\n",
            " 1 0 0 1 2 0 0 0 1 1 0 2 2 2 1 2 1 1 0 0 1 2 2 2 1 2 0 2 2 1 0 2 1 2 1 2 0\n",
            " 2 0 2 1 1 0 0 0 2 2 0 1 2 1 1 2 2 2 2 1 0 1 2 2 0 2 2 0 0 1 0 2 1 2 1 2 1\n",
            " 0 1 2 2 2 2 1 1 2 1 2 0 2 2 0 1 2 0 1 0 1 1 0 1 0 1 1 1 1 0 0 2 2 0 0 1 1\n",
            " 1 2 0 1 1 1 0 1 0 1 0 0 1 1 2 1 1 0 2 0 2 0 1 0 2 0 1 0 0 2 2 1 0 1 2 1 0\n",
            " 2 2 0 0 0 0 1 2 2 2 2 0 1 0 0 1 2 2 0 0 1 1 1 1 2 0 1 0 0 2 0 2 1 0 1 1 2\n",
            " 0 2 1]\n",
            "[1 0 2 2 0 1 2 1 0 2 1 2 1 0 2 0 0 2 1 2 1 0 0 2 2 0 1 2 2 1 0 0 0 1 0 2 1\n",
            " 2 1 2 0 2 1 0 1 1 1 0 2 1 1 2 0 0 1 2 2 0 0 1 1 0 2 1 2 0 1 0 1 2 1 1 0 1\n",
            " 2 1 1 1 0 2 2 1 1 2 1 2 0 1 0 0 0 0 1 2 2 2 1 2 0 2 1 1 0 1 2 0 0 0 0 1 1\n",
            " 0 1 0 0 2 0 0 1 2 0 0 2 2 0 0 0 1 1 1 0 2 1 0 1 0 1 2 1 0 2 0 0 0 2 0 2 0\n",
            " 1 0 0 1 2 0 1 0 1 1 0 2 2 2 1 2 1 1 0 2 1 2 2 2 1 2 0 2 2 1 0 2 1 2 1 2 0\n",
            " 2 0 2 1 1 0 0 0 2 2 0 1 2 1 1 2 2 2 2 1 0 1 2 2 0 2 2 0 0 1 0 2 1 2 1 2 1\n",
            " 0 1 2 2 2 2 1 1 2 1 2 0 2 2 2 1 2 0 1 0 1 1 0 1 0 1 1 1 1 0 0 2 2 0 0 1 1\n",
            " 1 2 0 1 1 1 0 1 0 1 0 0 1 2 2 1 1 0 2 0 2 0 1 0 2 1 1 0 0 2 2 1 0 1 2 1 0\n",
            " 2 2 0 0 0 0 1 2 2 2 2 0 1 0 0 1 2 2 0 0 1 1 1 1 2 0 1 0 0 2 0 2 1 0 1 1 2\n",
            " 0 2 1]\n",
            "0.9821428571428571\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}